###  [:house:返回](README.md)
---


## 语言生成型人工智能或可阻碍科学研究
` 科海拾星` [轉載自GNews](https://gnews.org/zh-hans/2554736/)

【撰稿】纽约香草山农场健身部 文真
 ![](https://cdn.discordapp.com/attachments/902205163622776852/956563844661121124/image0.png) 
近期，《自然》杂志报道，美国密歇根大学发布一份关于新兴语言生成型人工智能技术的社会影响的报告。报告中，研究人员担心，算法生成的具有权威性的语言流可能会造成混乱和阻碍，并加剧对科学的不信任。
 
新兴语言生成型人工智能技术基于大型语言模型，使用从大量文本中生成流畅语言的机器学习算法，目的在于向人类一样进行总结、写作、翻译、回答问题，甚至生成代码。构建这类模型的大型科技公司，将这项技术用于聊天机器人和搜索引擎。
 
当语言生成型人工智能涉及科学领域时，有助于迅速查找信息。但是，机器学习算法可能存在缺陷，包含过时信息，忽略差别和不确定性，而且，语言生成的模型是非公开的，输入的学习文本可能是建立在部分数据集上。加之，与这些人工智能工具的互动非常个性化，每个用户都会得到他们自己生成的信息。当使用者没有意识到语言生成型人工智能的局限性，而依赖从这项技术中获得的信息时，他们可能得到有偏差的或者简化的、与复杂的现实相悖的科学论点。
 
这份报告特别建议，针对语言生成型人工智能在科学领域的应用，透明度至关重要。开发者应明确说明，在机器学习过程中使用了哪些文本，以及算法的逻辑。大型科学出版商应当参与这些人工智能工具的开发。科学家们应该警惕期刊或者资助人是否依靠这项技术寻找同行评审员，或评价稿件或资金审核。
 
[https://www.nature.com/articles/d41586-022-01191-3](https://www.nature.com/articles/d41586-022-01191-3)
 
校对/发稿：菩提树
 
![](https://cdn.discordapp.com/attachments/942466911881539646/970788410249846824/IMG_1279.JPG)

免责声明：本文内容仅代表作者个人观点，平台不承担任何法律风险。
  
- [ROL Foundation](https://rolfoundation.org/)
- [ROL Society](https://rolsociety.org/)
- [Terms of use](https://gnews.org/terms-of-use-3/)
- [Privacy Policy](https://gnews.org/privacy-policy/)
